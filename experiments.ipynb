{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-12-25T12:29:20.965153Z","iopub.status.busy":"2023-12-25T12:29:20.964666Z","iopub.status.idle":"2023-12-25T12:29:20.972728Z","shell.execute_reply":"2023-12-25T12:29:20.971533Z","shell.execute_reply.started":"2023-12-25T12:29:20.965120Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-01-06 15:57:59.473537: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["import datetime\n","import pandas as pd\n","import gymnasium as gym\n","import gym_anytrading\n","import numpy as np\n","import datetime\n","from gym_anytrading.envs import StocksEnv\n","import random\n","import numpy as np\n","from collections import deque\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM, Dropout\n","from keras.optimizers import Adam\n","import subprocess"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-12-25T12:25:22.230901Z","iopub.status.busy":"2023-12-25T12:25:22.230507Z","iopub.status.idle":"2023-12-25T12:25:22.239632Z","shell.execute_reply":"2023-12-25T12:25:22.238302Z","shell.execute_reply.started":"2023-12-25T12:25:22.230869Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(2335, 6)"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["df = gym_anytrading.datasets.STOCKS_GOOGL.copy()\n","df.shape"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","DatetimeIndex: 2335 entries, 2009-05-22 to 2018-08-29\n","Data columns (total 6 columns):\n"," #   Column     Non-Null Count  Dtype  \n","---  ------     --------------  -----  \n"," 0   Open       2335 non-null   float64\n"," 1   High       2335 non-null   float64\n"," 2   Low        2335 non-null   float64\n"," 3   Close      2335 non-null   float64\n"," 4   Adj Close  2335 non-null   float64\n"," 5   Volume     2335 non-null   int64  \n","dtypes: float64(5), int64(1)\n","memory usage: 127.7 KB\n"]}],"source":["df.info()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Open</th>\n","      <th>High</th>\n","      <th>Low</th>\n","      <th>Close</th>\n","      <th>Adj Close</th>\n","      <th>Volume</th>\n","      <th>TEMA</th>\n","      <th>ER</th>\n","      <th>RSI</th>\n","      <th>OBV</th>\n","      <th>STOCH</th>\n","    </tr>\n","    <tr>\n","      <th>Date</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2009-05-22</th>\n","      <td>198.528534</td>\n","      <td>199.524521</td>\n","      <td>196.196198</td>\n","      <td>196.946945</td>\n","      <td>196.946945</td>\n","      <td>3433700</td>\n","      <td>196.946945</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2009-05-26</th>\n","      <td>196.171173</td>\n","      <td>202.702698</td>\n","      <td>195.195190</td>\n","      <td>202.382385</td>\n","      <td>202.382385</td>\n","      <td>6202700</td>\n","      <td>201.859051</td>\n","      <td>0.000000</td>\n","      <td>100.000000</td>\n","      <td>6202700.0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2009-05-27</th>\n","      <td>203.023026</td>\n","      <td>206.136139</td>\n","      <td>202.607605</td>\n","      <td>202.982986</td>\n","      <td>202.982986</td>\n","      <td>6062500</td>\n","      <td>203.160949</td>\n","      <td>0.000000</td>\n","      <td>100.000000</td>\n","      <td>12265200.0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2009-05-28</th>\n","      <td>204.544540</td>\n","      <td>206.016022</td>\n","      <td>202.507507</td>\n","      <td>205.405411</td>\n","      <td>205.405411</td>\n","      <td>5332200</td>\n","      <td>205.100062</td>\n","      <td>0.000000</td>\n","      <td>100.000000</td>\n","      <td>17597400.0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2009-05-29</th>\n","      <td>206.261261</td>\n","      <td>208.823822</td>\n","      <td>205.555557</td>\n","      <td>208.823822</td>\n","      <td>208.823822</td>\n","      <td>5291100</td>\n","      <td>207.893821</td>\n","      <td>0.000000</td>\n","      <td>100.000000</td>\n","      <td>22888500.0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2009-06-01</th>\n","      <td>209.574570</td>\n","      <td>215.015015</td>\n","      <td>209.474472</td>\n","      <td>213.493500</td>\n","      <td>213.493500</td>\n","      <td>6638100</td>\n","      <td>211.763625</td>\n","      <td>0.000000</td>\n","      <td>100.000000</td>\n","      <td>29526600.0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2009-06-02</th>\n","      <td>213.338333</td>\n","      <td>215.195190</td>\n","      <td>211.911911</td>\n","      <td>214.414413</td>\n","      <td>214.414413</td>\n","      <td>5241900</td>\n","      <td>214.155646</td>\n","      <td>0.000000</td>\n","      <td>100.000000</td>\n","      <td>34768500.0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2009-06-03</th>\n","      <td>213.213211</td>\n","      <td>216.446442</td>\n","      <td>212.212219</td>\n","      <td>216.041046</td>\n","      <td>216.041046</td>\n","      <td>7058500</td>\n","      <td>216.149464</td>\n","      <td>0.000000</td>\n","      <td>100.000000</td>\n","      <td>41827000.0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2009-06-04</th>\n","      <td>217.867874</td>\n","      <td>220.840836</td>\n","      <td>217.467468</td>\n","      <td>220.360367</td>\n","      <td>220.360367</td>\n","      <td>7268900</td>\n","      <td>219.240719</td>\n","      <td>0.000000</td>\n","      <td>100.000000</td>\n","      <td>49095900.0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2009-06-05</th>\n","      <td>222.757751</td>\n","      <td>223.893890</td>\n","      <td>219.949951</td>\n","      <td>222.382385</td>\n","      <td>222.382385</td>\n","      <td>7354200</td>\n","      <td>221.906262</td>\n","      <td>0.000000</td>\n","      <td>100.000000</td>\n","      <td>56450100.0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2009-06-08</th>\n","      <td>219.969971</td>\n","      <td>220.680679</td>\n","      <td>217.277283</td>\n","      <td>219.604599</td>\n","      <td>219.604599</td>\n","      <td>6191200</td>\n","      <td>222.132117</td>\n","      <td>0.803086</td>\n","      <td>86.347004</td>\n","      <td>50258900.0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2009-06-09</th>\n","      <td>219.509506</td>\n","      <td>220.470474</td>\n","      <td>216.096100</td>\n","      <td>218.028030</td>\n","      <td>218.028030</td>\n","      <td>6503200</td>\n","      <td>221.378549</td>\n","      <td>0.642417</td>\n","      <td>79.696337</td>\n","      <td>43755700.0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2009-06-10</th>\n","      <td>218.333328</td>\n","      <td>219.164169</td>\n","      <td>213.548553</td>\n","      <td>216.516510</td>\n","      <td>216.516510</td>\n","      <td>6711000</td>\n","      <td>220.056005</td>\n","      <td>0.535657</td>\n","      <td>73.825376</td>\n","      <td>37044700.0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2009-06-11</th>\n","      <td>216.101105</td>\n","      <td>217.082077</td>\n","      <td>214.399399</td>\n","      <td>214.714722</td>\n","      <td>214.714722</td>\n","      <td>5724600</td>\n","      <td>218.271467</td>\n","      <td>0.377742</td>\n","      <td>67.447029</td>\n","      <td>31320100.0</td>\n","      <td>68.015387</td>\n","    </tr>\n","    <tr>\n","      <th>2009-06-12</th>\n","      <td>213.643646</td>\n","      <td>214.064072</td>\n","      <td>210.815811</td>\n","      <td>212.632629</td>\n","      <td>212.632629</td>\n","      <td>5830900</td>\n","      <td>216.096741</td>\n","      <td>0.163410</td>\n","      <td>60.899229</td>\n","      <td>25489200.0</td>\n","      <td>60.760379</td>\n","    </tr>\n","    <tr>\n","      <th>2009-06-15</th>\n","      <td>210.960968</td>\n","      <td>210.960968</td>\n","      <td>207.207214</td>\n","      <td>208.593597</td>\n","      <td>208.593597</td>\n","      <td>7466300</td>\n","      <td>212.876214</td>\n","      <td>0.216067</td>\n","      <td>50.630698</td>\n","      <td>18022900.0</td>\n","      <td>28.457781</td>\n","    </tr>\n","    <tr>\n","      <th>2009-06-16</th>\n","      <td>209.864868</td>\n","      <td>210.755753</td>\n","      <td>207.917923</td>\n","      <td>208.208206</td>\n","      <td>208.208206</td>\n","      <td>6093300</td>\n","      <td>210.498502</td>\n","      <td>0.280289</td>\n","      <td>49.768396</td>\n","      <td>11929600.0</td>\n","      <td>26.655742</td>\n","    </tr>\n","    <tr>\n","      <th>2009-06-17</th>\n","      <td>208.303299</td>\n","      <td>210.070068</td>\n","      <td>205.985992</td>\n","      <td>207.787781</td>\n","      <td>207.787781</td>\n","      <td>6973200</td>\n","      <td>208.719925</td>\n","      <td>0.394215</td>\n","      <td>48.792134</td>\n","      <td>4956400.0</td>\n","      <td>12.172448</td>\n","    </tr>\n","    <tr>\n","      <th>2009-06-18</th>\n","      <td>208.048050</td>\n","      <td>209.554550</td>\n","      <td>206.706711</td>\n","      <td>207.237244</td>\n","      <td>207.237244</td>\n","      <td>6164200</td>\n","      <td>207.324601</td>\n","      <td>0.764432</td>\n","      <td>47.478740</td>\n","      <td>-1207800.0</td>\n","      <td>6.987152</td>\n","    </tr>\n","    <tr>\n","      <th>2009-06-19</th>\n","      <td>209.314316</td>\n","      <td>210.440445</td>\n","      <td>207.497498</td>\n","      <td>210.255249</td>\n","      <td>210.255249</td>\n","      <td>8509600</td>\n","      <td>207.659133</td>\n","      <td>0.667678</td>\n","      <td>54.680638</td>\n","      <td>7301800.0</td>\n","      <td>23.840079</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                  Open        High         Low       Close   Adj Close  \\\n","Date                                                                     \n","2009-05-22  198.528534  199.524521  196.196198  196.946945  196.946945   \n","2009-05-26  196.171173  202.702698  195.195190  202.382385  202.382385   \n","2009-05-27  203.023026  206.136139  202.607605  202.982986  202.982986   \n","2009-05-28  204.544540  206.016022  202.507507  205.405411  205.405411   \n","2009-05-29  206.261261  208.823822  205.555557  208.823822  208.823822   \n","2009-06-01  209.574570  215.015015  209.474472  213.493500  213.493500   \n","2009-06-02  213.338333  215.195190  211.911911  214.414413  214.414413   \n","2009-06-03  213.213211  216.446442  212.212219  216.041046  216.041046   \n","2009-06-04  217.867874  220.840836  217.467468  220.360367  220.360367   \n","2009-06-05  222.757751  223.893890  219.949951  222.382385  222.382385   \n","2009-06-08  219.969971  220.680679  217.277283  219.604599  219.604599   \n","2009-06-09  219.509506  220.470474  216.096100  218.028030  218.028030   \n","2009-06-10  218.333328  219.164169  213.548553  216.516510  216.516510   \n","2009-06-11  216.101105  217.082077  214.399399  214.714722  214.714722   \n","2009-06-12  213.643646  214.064072  210.815811  212.632629  212.632629   \n","2009-06-15  210.960968  210.960968  207.207214  208.593597  208.593597   \n","2009-06-16  209.864868  210.755753  207.917923  208.208206  208.208206   \n","2009-06-17  208.303299  210.070068  205.985992  207.787781  207.787781   \n","2009-06-18  208.048050  209.554550  206.706711  207.237244  207.237244   \n","2009-06-19  209.314316  210.440445  207.497498  210.255249  210.255249   \n","\n","             Volume        TEMA        ER         RSI         OBV      STOCH  \n","Date                                                                          \n","2009-05-22  3433700  196.946945  0.000000    0.000000         0.0   0.000000  \n","2009-05-26  6202700  201.859051  0.000000  100.000000   6202700.0   0.000000  \n","2009-05-27  6062500  203.160949  0.000000  100.000000  12265200.0   0.000000  \n","2009-05-28  5332200  205.100062  0.000000  100.000000  17597400.0   0.000000  \n","2009-05-29  5291100  207.893821  0.000000  100.000000  22888500.0   0.000000  \n","2009-06-01  6638100  211.763625  0.000000  100.000000  29526600.0   0.000000  \n","2009-06-02  5241900  214.155646  0.000000  100.000000  34768500.0   0.000000  \n","2009-06-03  7058500  216.149464  0.000000  100.000000  41827000.0   0.000000  \n","2009-06-04  7268900  219.240719  0.000000  100.000000  49095900.0   0.000000  \n","2009-06-05  7354200  221.906262  0.000000  100.000000  56450100.0   0.000000  \n","2009-06-08  6191200  222.132117  0.803086   86.347004  50258900.0   0.000000  \n","2009-06-09  6503200  221.378549  0.642417   79.696337  43755700.0   0.000000  \n","2009-06-10  6711000  220.056005  0.535657   73.825376  37044700.0   0.000000  \n","2009-06-11  5724600  218.271467  0.377742   67.447029  31320100.0  68.015387  \n","2009-06-12  5830900  216.096741  0.163410   60.899229  25489200.0  60.760379  \n","2009-06-15  7466300  212.876214  0.216067   50.630698  18022900.0  28.457781  \n","2009-06-16  6093300  210.498502  0.280289   49.768396  11929600.0  26.655742  \n","2009-06-17  6973200  208.719925  0.394215   48.792134   4956400.0  12.172448  \n","2009-06-18  6164200  207.324601  0.764432   47.478740  -1207800.0   6.987152  \n","2009-06-19  8509600  207.659133  0.667678   54.680638   7301800.0  23.840079  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["from finta import TA\n","df['TEMA'] = TA.TEMA(df, 12) # Triple Exponential Moving Average --> in ce directie se indreapta pretul pe parcursul a 12 zile cu accent mare pe ultimele zile\n","df['ER'] = TA.ER(df) # Kaufman Efficiency Indicator --> confirmare a trendului (-1,1) : -1 downtrend, 1 uptrend, aprox 0 random (trend confirmation)\n","df['RSI'] = TA.RSI(df) # Relative Strength Index --> intre 0 si 100, 30-70 intervalul de interes, 30-0 oversold, 70-100 overbought (trend confirmation)\n","df['OBV'] = TA.OBV(df) # On Balance Volume --> confirmare a trendului (trend confirmation) --> se bazeaza pe volumul tranzactiilor\n","df['STOCH'] = TA.STOCH(df) # Stochastic Oscillator --> confirmare a trendului (trend confirmation) --> intre 0 si 100, 20-80 intervalul de interes, 20-0 oversold, 80-100 overbought\n","df.fillna(0, inplace=True)\n","df.head(20)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def evaluate(start_index, end_index,test_env,model,iterations=10):\n","    test_env.reset()    \n","    test_env.frame_bound = (start_index,end_index)\n","    total_profit = 0\n","    total_reward = 0\n","    for it in tqdm.tqdm(range(iterations)):\n","        obs = test_env.reset()\n","        state = obs[0]\n","        timestep = 0\n","        while True:\n","            # print(model.predict(state.reshape(1,12,11),verbose=0).ravel())\n","            # print(np.argmax(model.predict(state.reshape(1,12,11),verbose=0).ravel()))\n","            print(timestep)\n","            timestep += 1\n","            action = np.argmax(model.predict(state.reshape(1,12,11),verbose=0).ravel())\n","            next_state, reward,terminal, done, info = test_env.step(action)\n","            initial_state = next_state\n","            if done:\n","                print(\"info\", info)\n","                total_profit += info['total_profit']\n","                total_reward += info['total_reward']\n","                break\n","        test_env.render_all()\n","    \n","    return total_profit/iterations,total_reward/iterations\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Agent Initialized\n","\n"]}],"source":["from dqn import Agent, Utils\n","from environment import CustomTradingEnv\n","agent = Agent(possible_actions=[0,1],starting_mem_len=100000,max_mem_len=400000,starting_epsilon = 1, learn_rate = .0005)\n","env = CustomTradingEnv(df=df,window_size=12,frame_bound=(12,1900))\n","utils = Utils()\n","last_100_avg = [-21]\n","scores = deque(maxlen = 100)\n","max_score = -float('inf')"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  1%|          | 9/1000 [00:00<00:11, 85.28it/s]"]},{"name":"stdout","output_type":"stream","text":["{'total_reward': 292.54380900000024, 'total_profit': 0.001498714677161033, 'position': <Positions.Long: 1>}\n","1887\n","\n","Episode: 0\n","Epsilon: 1\n","{'total_reward': 424.70779600000037, 'total_profit': 0.0012948042232010404, 'position': <Positions.Long: 1>}\n","3774\n","\n","Episode: 1\n","Epsilon: 1\n","{'total_reward': 329.0302859999992, 'total_profit': 0.001776756939853867, 'position': <Positions.Long: 1>}\n","5661\n","\n","Episode: 2\n","Epsilon: 1\n","{'total_reward': 294.0715120000013, 'total_profit': 0.0015811378070066833, 'position': <Positions.Long: 1>}\n","7548\n","\n","Episode: 3\n","Epsilon: 1\n","{'total_reward': 370.17112900000086, 'total_profit': 0.0016619092279323284, 'position': <Positions.Short: 0>}\n","9435\n","\n","Episode: 4\n","Epsilon: 1\n","{'total_reward': 346.7747260000004, 'total_profit': 0.001748706555284885, 'position': <Positions.Long: 1>}\n","11322\n","\n","Episode: 5\n","Epsilon: 1\n","{'total_reward': 400.58124600000036, 'total_profit': 0.0022012771392841833, 'position': <Positions.Short: 0>}\n","13209\n","\n","Episode: 6\n","Epsilon: 1\n","{'total_reward': 598.0277189999985, 'total_profit': 0.0038122538951796884, 'position': <Positions.Short: 0>}\n","15096\n","\n","Episode: 7\n","Epsilon: 1\n","{'total_reward': -35.98121100000009, 'total_profit': 0.001308415855247752, 'position': <Positions.Short: 0>}\n","16983\n","\n","Episode: 8\n","Epsilon: 1\n","{'total_reward': 208.54971199999898, 'total_profit': 0.002004494232780995, 'position': <Positions.Long: 1>}\n","18870\n","\n","Episode: 9\n","Epsilon: 1\n","{'total_reward': 58.72280600000062, 'total_profit': 0.0011605545169761599, 'position': <Positions.Long: 1>}\n","20757\n","\n","Episode: 10\n","Epsilon: 1\n","{'total_reward': 475.59225500000065, 'total_profit': 0.0021277388080688524, 'position': <Positions.Short: 0>}\n","22644\n","\n","Episode: 11\n","Epsilon: 1\n","{'total_reward': 199.97211499999958, 'total_profit': 0.0011691921685795651, 'position': <Positions.Long: 1>}\n","24531\n","\n","Episode: 12\n","Epsilon: 1\n","{'total_reward': 387.502829, 'total_profit': 0.0028237504986211638, 'position': <Positions.Short: 0>}\n","26418\n","\n","Episode: 13\n","Epsilon: 1\n","{'total_reward': 299.64706500000005, 'total_profit': 0.0011497385154370424, 'position': <Positions.Short: 0>}\n","28305\n","\n","Episode: 14\n","Epsilon: 1\n","{'total_reward': 251.74275900000055, 'total_profit': 0.001732205264693229, 'position': <Positions.Short: 0>}\n","30192\n","\n","Episode: 15\n","Epsilon: 1\n"]},{"name":"stderr","output_type":"stream","text":["  2%|▏         | 18/1000 [00:00<00:11, 86.62it/s]"]},{"name":"stdout","output_type":"stream","text":["{'total_reward': 316.257019000001, 'total_profit': 0.0019052239128427072, 'position': <Positions.Long: 1>}\n","32079\n","\n","Episode: 16\n","Epsilon: 1\n","{'total_reward': 258.7774589999998, 'total_profit': 0.001194834432486924, 'position': <Positions.Short: 0>}\n","33966\n","\n","Episode: 17\n","Epsilon: 1\n","{'total_reward': 433.85519500000066, 'total_profit': 0.0018407478001560645, 'position': <Positions.Long: 1>}\n","35853\n","\n","Episode: 18\n","Epsilon: 1\n"]},{"name":"stderr","output_type":"stream","text":["  3%|▎         | 28/1000 [00:00<00:10, 89.62it/s]"]},{"name":"stdout","output_type":"stream","text":["{'total_reward': 415.2072229999999, 'total_profit': 0.0014309077226162753, 'position': <Positions.Short: 0>}\n","37740\n","\n","Episode: 19\n","Epsilon: 1\n","{'total_reward': 157.5632279999998, 'total_profit': 0.0012838146859531397, 'position': <Positions.Long: 1>}\n","39627\n","\n","Episode: 20\n","Epsilon: 1\n","{'total_reward': 260.75760400000047, 'total_profit': 0.0015587908988034455, 'position': <Positions.Long: 1>}\n","41514\n","\n","Episode: 21\n","Epsilon: 1\n","{'total_reward': 127.70060899999976, 'total_profit': 0.0014764867252256711, 'position': <Positions.Short: 0>}\n","43401\n","\n","Episode: 22\n","Epsilon: 1\n","{'total_reward': 361.64040699999964, 'total_profit': 0.0014535906022996887, 'position': <Positions.Short: 0>}\n","45288\n","\n","Episode: 23\n","Epsilon: 1\n","{'total_reward': 327.6517849999998, 'total_profit': 0.0015260156715833505, 'position': <Positions.Short: 0>}\n","47175\n","\n","Episode: 24\n","Epsilon: 1\n","{'total_reward': 194.1393010000005, 'total_profit': 0.0014127458997003823, 'position': <Positions.Short: 0>}\n","49062\n","\n","Episode: 25\n","Epsilon: 1\n","\n","Weights saved!\n","{'total_reward': 236.37435399999947, 'total_profit': 0.0012410221797528997, 'position': <Positions.Long: 1>}\n","50949\n","\n","Episode: 26\n","Epsilon: 1\n","{'total_reward': 438.51543300000014, 'total_profit': 0.002280414657685864, 'position': <Positions.Long: 1>}\n","52836\n","\n","Episode: 27\n","Epsilon: 1\n","{'total_reward': 405.6662949999995, 'total_profit': 0.002299826476864383, 'position': <Positions.Short: 0>}\n","54723\n","\n","Episode: 28\n","Epsilon: 1\n","{'total_reward': 134.61735499999986, 'total_profit': 0.0012851819405682097, 'position': <Positions.Long: 1>}\n","56610\n","\n","Episode: 29\n","Epsilon: 1\n","{'total_reward': 248.23351800000114, 'total_profit': 0.0015567548060706744, 'position': <Positions.Long: 1>}\n","58497\n","\n","Episode: 30\n","Epsilon: 1\n","{'total_reward': 325.6555559999988, 'total_profit': 0.0011998698408531724, 'position': <Positions.Long: 1>}\n","60384\n","\n","Episode: 31\n","Epsilon: 1\n","{'total_reward': 342.1526440000007, 'total_profit': 0.0017960445195447153, 'position': <Positions.Long: 1>}\n","62271\n","\n","Episode: 32\n","Epsilon: 1\n","{'total_reward': 142.91191799999976, 'total_profit': 0.0010686760755346672, 'position': <Positions.Long: 1>}\n","64158\n","\n","Episode: 33\n","Epsilon: 1\n","{'total_reward': 139.55989499999885, 'total_profit': 0.0009749953173925357, 'position': <Positions.Short: 0>}\n","66045\n","\n","Episode: 34\n","Epsilon: 1\n","{'total_reward': 237.0558710000007, 'total_profit': 0.0016411402456724697, 'position': <Positions.Short: 0>}\n","67932\n","\n","Episode: 35\n","Epsilon: 1\n","{'total_reward': 331.9949619999998, 'total_profit': 0.001789911253002662, 'position': <Positions.Long: 1>}\n","69819\n","\n","Episode: 36\n","Epsilon: 1\n"]},{"name":"stderr","output_type":"stream","text":["  4%|▍         | 38/1000 [00:00<00:10, 91.27it/s]"]},{"name":"stdout","output_type":"stream","text":["{'total_reward': 365.3726760000008, 'total_profit': 0.0015406839838233404, 'position': <Positions.Short: 0>}\n","71706\n","\n","Episode: 37\n","Epsilon: 1\n","{'total_reward': 254.82697699999972, 'total_profit': 0.0014047774338013718, 'position': <Positions.Short: 0>}\n","73593\n","\n","Episode: 38\n","Epsilon: 1\n","{'total_reward': 519.1493360000011, 'total_profit': 0.0023865390439762823, 'position': <Positions.Long: 1>}\n","75480\n","\n","Episode: 39\n","Epsilon: 1\n"]},{"name":"stderr","output_type":"stream","text":["  5%|▍         | 48/1000 [00:00<00:10, 92.10it/s]"]},{"name":"stdout","output_type":"stream","text":["{'total_reward': 296.5404309999994, 'total_profit': 0.0023251790824454816, 'position': <Positions.Short: 0>}\n","77367\n","\n","Episode: 40\n","Epsilon: 1\n","{'total_reward': 158.80140900000006, 'total_profit': 0.0012011829246225889, 'position': <Positions.Short: 0>}\n","79254\n","\n","Episode: 41\n","Epsilon: 1\n","{'total_reward': 117.16711700000056, 'total_profit': 0.0008629898745068508, 'position': <Positions.Short: 0>}\n","81141\n","\n","Episode: 42\n","Epsilon: 1\n","{'total_reward': 461.4347970000005, 'total_profit': 0.0026450149491592237, 'position': <Positions.Long: 1>}\n","83028\n","\n","Episode: 43\n","Epsilon: 1\n","{'total_reward': 210.70347600000056, 'total_profit': 0.0010741320799628213, 'position': <Positions.Short: 0>}\n","84915\n","\n","Episode: 44\n","Epsilon: 1\n","{'total_reward': 193.8005030000001, 'total_profit': 0.000878984207083395, 'position': <Positions.Short: 0>}\n","86802\n","\n","Episode: 45\n","Epsilon: 1\n","{'total_reward': 242.79726900000003, 'total_profit': 0.001687914721869908, 'position': <Positions.Long: 1>}\n","88689\n","\n","Episode: 46\n","Epsilon: 1\n","{'total_reward': -23.70778499999966, 'total_profit': 0.0008462191724314534, 'position': <Positions.Short: 0>}\n","90576\n","\n","Episode: 47\n","Epsilon: 1\n","{'total_reward': 438.6848300000006, 'total_profit': 0.0023027116155025103, 'position': <Positions.Short: 0>}\n","92463\n","\n","Episode: 48\n","Epsilon: 1\n","{'total_reward': 189.37887899999993, 'total_profit': 0.0011454987945860122, 'position': <Positions.Long: 1>}\n","94350\n","\n","Episode: 49\n","Epsilon: 1\n","{'total_reward': 341.63256500000057, 'total_profit': 0.0018013109323275548, 'position': <Positions.Long: 1>}\n","96237\n","\n","Episode: 50\n","Epsilon: 1\n","{'total_reward': 109.69769200000033, 'total_profit': 0.0011788969952916217, 'position': <Positions.Short: 0>}\n","98124\n","\n","Episode: 51\n","Epsilon: 1\n"]},{"name":"stderr","output_type":"stream","text":["/home/mircea/RL/proiect/dqn.py:143: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  tensor_dateset = TensorDataset(torch.tensor(np.array(states),dtype=torch.float32),torch.tensor(labels,dtype=torch.float32))\n","/home/mircea/RL/proiect/dqn.py:143: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  tensor_dateset = TensorDataset(torch.tensor(np.array(states),dtype=torch.float32),torch.tensor(labels,dtype=torch.float32))\n"]},{"name":"stdout","output_type":"stream","text":["{'total_reward': 166.5360409999987, 'total_profit': 0.0011598996692628628, 'position': <Positions.Short: 0>}\n","100011\n","\n","Episode: 52\n","Epsilon: 0.9999099999999996\n","\n","Weights saved!\n"]},{"name":"stderr","output_type":"stream","text":["  5%|▌         | 53/1000 [00:08<02:29,  6.33it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m timesteps \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mtotal_timesteps\n\u001b[1;32m      8\u001b[0m timee \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 9\u001b[0m score,info \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mplay_episode( env, agent,i, debug \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m#set debug to true for rendering\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(info)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(agent\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39mrewards))\n","File \u001b[0;32m~/RL/proiect/dqn.py:81\u001b[0m, in \u001b[0;36mUtils.play_episode\u001b[0;34m(self, env, agent, no_episode, debug)\u001b[0m\n\u001b[1;32m     79\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     score,done,info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake_step(env,agent,score, debug)\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n","File \u001b[0;32m~/RL/proiect/dqn.py:72\u001b[0m, in \u001b[0;36mUtils.take_step\u001b[0;34m(self, env, agent, score, debug)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m#9: If the threshold memory is satisfied, make the agent learn from memory\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(agent\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39mframes) \u001b[38;5;241m>\u001b[39m agent\u001b[38;5;241m.\u001b[39mstarting_mem_len:\n\u001b[0;32m---> 72\u001b[0m     agent\u001b[38;5;241m.\u001b[39mlearn(debug)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (score \u001b[38;5;241m+\u001b[39m next_frames_reward),\u001b[38;5;28;01mFalse\u001b[39;00m,info\n","File \u001b[0;32m~/RL/proiect/dqn.py:185\u001b[0m, in \u001b[0;36mAgent.learn\u001b[0;34m(self, debug)\u001b[0m\n\u001b[1;32m    183\u001b[0m next_states_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39marray(next_states),dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    184\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(states_tensor)\n\u001b[0;32m--> 185\u001b[0m next_state_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_target(next_states_tensor)\n\u001b[1;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Now we define our labels, or what the output should have been\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m   We want the output[action_taken] to be R_(t+1) + Qmax_(t+1) \"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m32\u001b[39m):\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;66;03m# trebuie modificat deoarece prezic pentru fiecare exemplu 12 etichete in loc de 1\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/rl_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m~/anaconda3/envs/rl_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/RL/proiect/dqn.py:25\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m h0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\n\u001b[1;32m     24\u001b[0m c0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\n\u001b[0;32m---> 25\u001b[0m x, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(x, (h0, c0))\n\u001b[1;32m     26\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(x[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n","File \u001b[0;32m~/anaconda3/envs/rl_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m~/anaconda3/envs/rl_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/rl_venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:879\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    876\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 879\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[1;32m    880\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    882\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    883\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import time\n","import matplotlib.pyplot as plt\n","import tqdm\n","env.reset()\n","for i in tqdm.tqdm(range(1000)):\n","    frames = [] # Saving the frames for the gif\n","    timesteps = agent.total_timesteps\n","    timee = time.time()\n","    score,info = utils.play_episode( env, agent,i, debug = True) #set debug to true for rendering\n","    print(info)\n","    print(len(agent.memory.rewards))\n","    # scores.append(score)\n","    # if score > max_score:\n","    #     max_score = score\n","        \n","    print('\\nEpisode: ' + str(i))\n","    # print('Steps: ' + str(agent.total_timesteps - timesteps))\n","    # print('Duration: ' + str(time.time() - timee))\n","    # print('Score: ' + str(score))\n","    # print('Max Score: ' + str(max_score))\n","    print('Epsilon: ' + str(agent.epsilon))\n","    \n","        \n","    # if i%100==0 and i!=0:\n","    #     last_100_avg.append(sum(scores)/len(scores))\n","    #     plt.plot(np.arange(0,i+1,100),last_100_avg)\n","    #     plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["evaluate(2312,df.shape[0],env,agent.model)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":533900,"sourceId":976925,"sourceType":"datasetVersion"}],"dockerImageVersionId":30626,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
